{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BY_EDjAGHOMT"
      },
      "source": [
        "# PRO LEVEL CHALLENGE 2: Clean Data > Big Models (NER Check)\n",
        "\n",
        "**The Problem:** Simple keyword searches are \"dumb.\" If you search for \"Apple,\" you might get news about fruit or pie. If you search for \"Amazon,\" you might get rainforest news.\n",
        "\n",
        "**Your Mission:** Implement a Named Entity Recognition (NER) check using **spaCy**. Only keep articles where the entity type is **ORG** (Organization)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-Qo88l3HOMX"
      },
      "source": [
        "## Setup: Install spaCy and Download Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2DJ3eWBOHOMZ",
        "outputId": "ceecf3bd-1436-43e7-ddbf-908d70c5b1b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… spaCy model loaded successfully\n"
          ]
        }
      ],
      "source": [
        "# Install spaCy and download English model\n",
        "# !pip install spacy\n",
        "# !python -m spacy download en_core_web_sm\n",
        "\n",
        "import spacy\n",
        "import pandas as pd\n",
        "\n",
        "# Load spaCy model\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "print(\"âœ… spaCy model loaded successfully\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Understanding Named Entities\n",
        "\n",
        "spaCy scans text and identifies \"Entities.\" For financial data, we care about:\n",
        "- **ORG**: Organizations (Companies, agencies)\n",
        "- **GPE**: Geopolitical entities (Countries, cities)\n",
        "- **PERSON**: People names\n",
        "- **MONEY**: Monetary values\n",
        "\n",
        "**Goal:** If \"Apple\" is labeled as a fruit (no label) or \"Amazon\" is labeled as a **LOC** (Location), we discard it."
      ],
      "metadata": {
        "id": "iLkQvtoZISak"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8xNRqsHDHOMe",
        "outputId": "962e871f-a41d-4951-a9c3-1339573d3dd8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entity Detection Examples:\n",
            "============================================================\n",
            "\n",
            "Text: Apple Inc. reports record earnings in Q4\n",
            "  - 'Apple Inc.' â†’ ORG\n",
            "  - 'Q4' â†’ GPE\n",
            "\n",
            "Text: The Amazon rainforest is facing deforestation\n",
            "  - 'Amazon' â†’ ORG\n",
            "\n",
            "Text: Amazon Web Services expands cloud infrastructure\n",
            "  - 'Amazon Web Services' â†’ ORG\n",
            "\n",
            "Text: I bought an apple from the grocery store\n",
            "  - No entities found\n",
            "\n",
            "Text: Tesla opens new factory in Austin, Texas\n",
            "  - 'Austin' â†’ GPE\n",
            "  - 'Texas' â†’ GPE\n",
            "\n",
            "Text: Visit the Tesla museum in New York\n",
            "  - 'Tesla' â†’ NORP\n",
            "  - 'New York' â†’ GPE\n"
          ]
        }
      ],
      "source": [
        "# Example: Identify entities in sample texts\n",
        "sample_texts = [\n",
        "    \"Apple Inc. reports record earnings in Q4\",\n",
        "    \"The Amazon rainforest is facing deforestation\",\n",
        "    \"Amazon Web Services expands cloud infrastructure\",\n",
        "    \"I bought an apple from the grocery store\",\n",
        "    \"Tesla opens new factory in Austin, Texas\",\n",
        "    \"Visit the Tesla museum in New York\"\n",
        "]\n",
        "\n",
        "print(\"Entity Detection Examples:\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "for text in sample_texts:\n",
        "    doc = nlp(text)\n",
        "    print(f\"\\nText: {text}\")\n",
        "    if doc.ents:\n",
        "        for ent in doc.ents:\n",
        "            print(f\"  - '{ent.text}' â†’ {ent.label_}\")\n",
        "    else:\n",
        "        print(\"  - No entities found\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> ### The \"Ambiguity\" Challenge (False Positives)\n",
        ">\n",
        "> Even with NER, some \"noise\" can slip through. For example, a basic model might still label the **Amazon Rainforest** or **Apple trees** as an **ORG** (Organization) because it sees these names used as companies 90% of the time in news data."
      ],
      "metadata": {
        "id": "TfhuArmpJjC_"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zrm7rTlgHOMf"
      },
      "source": [
        "### Step 1: Create the NER Filter\n",
        "We need a function that returns `True` only if our target company is found and labeled specifically as an **Organization (ORG)**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NrEadAiQHOMh",
        "outputId": "4312de83-6650-4106-e74a-0fd897a35b89"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing NER Filter:\n",
            "============================================================\n",
            "âœ… 'Apple Inc. releases new iPhone' â†’ True (expected True)\n",
            "âœ… 'I ate an apple for lunch' â†’ False (expected False)\n",
            "âœ… 'Amazon expands its e-commerce platform' â†’ True (expected True)\n",
            "âŒ 'The Amazon river is the longest' â†’ True (expected False)\n"
          ]
        }
      ],
      "source": [
        "def check_entity_is_org(text, company_name):\n",
        "    \"\"\"\n",
        "    Check if the company_name in the text is classified as an ORG.\n",
        "    \"\"\"\n",
        "    doc = nlp(text)\n",
        "\n",
        "    for ent in doc.ents:\n",
        "        # Check if entity text contains company name (case-insensitive)\n",
        "        if company_name.lower() in ent.text.lower():\n",
        "            if ent.label_ == 'ORG':\n",
        "                return True\n",
        "            else:\n",
        "                return False  # Found but not an ORG (e.g., a Location)\n",
        "\n",
        "    return False  # Company name not found as an entity at all\n",
        "\n",
        "# Test the function\n",
        "test_cases = [\n",
        "    (\"Apple Inc. releases new iPhone\", \"Apple\", True),\n",
        "    (\"I ate an apple for lunch\", \"Apple\", False),\n",
        "    (\"Amazon expands its e-commerce platform\", \"Amazon\", True),\n",
        "    (\"The Amazon river is the longest\", \"Amazon\", False),\n",
        "]\n",
        "\n",
        "print(\"Testing NER Filter:\")\n",
        "print(\"=\" * 60)\n",
        "for text, company, expected in test_cases:\n",
        "    result = check_entity_is_org(text, company)\n",
        "    status = \"âœ…\" if result == expected else \"âŒ\"\n",
        "    print(f\"{status} '{text}' â†’ {result} (expected {expected})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5-m_IcIHOMj"
      },
      "source": [
        "### Step 2: Cleaning the News Dataset\n",
        "Now we apply this filter to a dataframe. This mimics your actual pipeline where you fetch raw headlines and need to prune the \"noise.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vv3HYvWtHOMk",
        "outputId": "2d74d12a-4e55-42cf-9bfc-6a2c1cbbc938"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtered dataset: 7 articles (removed 3 non-ORG)\n",
            "\n",
            "Cleaned News for Analysis:\n",
            "                                       headline    company\n",
            "0              Apple announces new product line      Apple\n",
            "2          Amazon stock surges on earnings beat     Amazon\n",
            "3        Amazon rainforest conservation efforts     Amazon\n",
            "6              Microsoft launches AI initiative  Microsoft\n",
            "7              Google reports strong ad revenue     Google\n",
            "8  Trip to New York and visiting Google offices     Google\n",
            "9                  Apple trees need proper care      Apple\n"
          ]
        }
      ],
      "source": [
        "# Create sample news dataset with mixed contexts\n",
        "news_data = {\n",
        "    'headline': [\n",
        "        'Apple announces new product line',\n",
        "        'How to make apple pie at home',\n",
        "        'Amazon stock surges on earnings beat',\n",
        "        'Amazon rainforest conservation efforts',\n",
        "        'Tesla unveils new electric vehicle',\n",
        "        'Visit the Tesla museum in Belgrade',\n",
        "        'Microsoft launches AI initiative',\n",
        "        'Google reports strong ad revenue',\n",
        "        'Trip to New York and visiting Google offices',\n",
        "        'Apple trees need proper care'\n",
        "    ],\n",
        "    'company': ['Apple', 'Apple', 'Amazon', 'Amazon', 'Tesla',\n",
        "               'Tesla', 'Microsoft', 'Google', 'Google', 'Apple']\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(news_data)\n",
        "\n",
        "# Apply NER filter\n",
        "df['is_org'] = df.apply(\n",
        "    lambda row: check_entity_is_org(row['headline'], row['company']),\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "# Filter to keep only ORG entities\n",
        "df_filtered = df[df['is_org'] == True].copy()\n",
        "\n",
        "print(f\"Filtered dataset: {len(df_filtered)} articles (removed {len(df) - len(df_filtered)} non-ORG)\")\n",
        "print(\"\\nCleaned News for Analysis:\")\n",
        "print(df_filtered[['headline', 'company']])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> ### The \"Ambiguity\" Challenge (False Positives)\n",
        ">\n",
        "> **How to fix this:** To reach 100% accuracy, professionals often use a \"Double Check\" methodâ€”combining NER with **negative keywords** (like \"tree\" or \"rainforest\") to discard remaining non-business articles."
      ],
      "metadata": {
        "id": "qWfPOyQMKk_e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def check_entity_is_org_refined(text, company_name):\n",
        "    \"\"\"\n",
        "    Enhanced filter that uses both NER and keyword exclusion\n",
        "    to remove non-business news.\n",
        "    \"\"\"\n",
        "    # 1. Define 'Noise' keywords that don't belong in stock news\n",
        "    noise_keywords = ['rainforest', 'river', 'tree', 'fruit', 'pie', 'recipe', 'care']\n",
        "\n",
        "    # 2. Pre-filter: if any noise word exists, reject immediately\n",
        "    if any(word in text.lower() for word in noise_keywords):\n",
        "        return False\n",
        "\n",
        "    doc = nlp(text)\n",
        "\n",
        "    # 3. Standard NER check\n",
        "    for ent in doc.ents:\n",
        "        if company_name.lower() in ent.text.lower():\n",
        "            # Only keep if strictly identified as an Organization\n",
        "            return ent.label_ == 'ORG'\n",
        "\n",
        "    return False\n",
        "\n",
        "# Re-apply the refined filter to your DataFrame\n",
        "df['is_org_refined'] = df.apply(\n",
        "    lambda row: check_entity_is_org_refined(row['headline'], row['company']),\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "# Show the results\n",
        "df_final = df[df['is_org_refined'] == True].copy()\n",
        "print(f\"âœ… Final Cleaned Dataset: {len(df_final)} articles\")\n",
        "print(df_final[['headline', 'company']])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wp2ykQEpK0FP",
        "outputId": "795c9482-110b-48e0-a7dc-93ca5b1b4155"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Final Cleaned Dataset: 5 articles\n",
            "                                       headline    company\n",
            "0              Apple announces new product line      Apple\n",
            "2          Amazon stock surges on earnings beat     Amazon\n",
            "6              Microsoft launches AI initiative  Microsoft\n",
            "7              Google reports strong ad revenue     Google\n",
            "8  Trip to New York and visiting Google offices     Google\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-W_Wt7LiHOMm",
        "outputId": "25f5dc03-d88a-4b45-bbad-8fd3109c97cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset with NER check:\n",
            "                                       headline    company  is_org\n",
            "0              Apple announces new product line      Apple    True\n",
            "1                 How to make apple pie at home      Apple   False\n",
            "2          Amazon stock surges on earnings beat     Amazon    True\n",
            "3        Amazon rainforest conservation efforts     Amazon   False\n",
            "4            Tesla unveils new electric vehicle      Tesla   False\n",
            "5            Visit the Tesla museum in Belgrade      Tesla   False\n",
            "6              Microsoft launches AI initiative  Microsoft    True\n",
            "7              Google reports strong ad revenue     Google    True\n",
            "8  Trip to New York and visiting Google offices     Google    True\n",
            "9                  Apple trees need proper care      Apple   False\n",
            "âœ… Filtered dataset: 5 articles (removed 5 non-ORG)\n",
            "Filtered articles:\n",
            "                                       headline    company\n",
            "0              Apple announces new product line      Apple\n",
            "2          Amazon stock surges on earnings beat     Amazon\n",
            "6              Microsoft launches AI initiative  Microsoft\n",
            "7              Google reports strong ad revenue     Google\n",
            "8  Trip to New York and visiting Google offices     Google\n"
          ]
        }
      ],
      "source": [
        "# Apply the Refined NER filter\n",
        "df['is_org'] = df.apply(\n",
        "    lambda row: check_entity_is_org_refined(row['headline'], row['company']),\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "print(\"Dataset with NER check:\")\n",
        "print(df)\n",
        "\n",
        "# Filter to keep only ORG entities\n",
        "df_filtered = df[df['is_org'] == True].copy()\n",
        "\n",
        "print(f\"âœ… Filtered dataset: {len(df_filtered)} articles (removed {len(df) - len(df_filtered)} non-ORG)\")\n",
        "print(\"Filtered articles:\")\n",
        "print(df_filtered[['headline', 'company']])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZwP2W4gnHOMn"
      },
      "source": [
        "## Batch Processing for Large Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ðŸš€ Speeding Up with Batch Processing\n",
        "\n",
        "When processing thousands of headlines, using `.apply()` can be slow because it loads the model for every single row.\n",
        "\n",
        "**How `nlp.pipe` works:**\n",
        "* It buffers headlines and processes them in parallel batches.\n",
        "* It is significantly faster than standard loops.\n",
        "* We integrated our **Noise Filter** directly into the batch loop to ensure data quality remains high."
      ],
      "metadata": {
        "id": "_BSmwE6wL_0V"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZJ1kPVBmHOMo",
        "outputId": "194b6ad0-854f-415d-e8de-db0df62d4a01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch processing results:\n",
            "                                       headline    company  is_org_batch\n",
            "0              Apple announces new product line      Apple          True\n",
            "1                 How to make apple pie at home      Apple         False\n",
            "2          Amazon stock surges on earnings beat     Amazon          True\n",
            "3        Amazon rainforest conservation efforts     Amazon         False\n",
            "4            Tesla unveils new electric vehicle      Tesla         False\n",
            "5            Visit the Tesla museum in Belgrade      Tesla         False\n",
            "6              Microsoft launches AI initiative  Microsoft          True\n",
            "7              Google reports strong ad revenue     Google          True\n",
            "8  Trip to New York and visiting Google offices     Google          True\n",
            "9                  Apple trees need proper care      Apple         False\n"
          ]
        }
      ],
      "source": [
        "# For large datasets, use spaCy's pipe for efficiency\n",
        "def filter_org_articles_batch(df, text_column='headline', company_column='company'):\n",
        "    \"\"\"\n",
        "    Efficiently filter articles using spaCy's pipe with noise reduction.\n",
        "    \"\"\"\n",
        "    results = []\n",
        "    noise_keywords = ['rainforest', 'river', 'tree', 'fruit', 'pie', 'recipe', 'care']\n",
        "\n",
        "    # Process in batches using nlp.pipe for high performance\n",
        "    docs = nlp.pipe(df[text_column])\n",
        "\n",
        "    for idx, doc in enumerate(docs):\n",
        "        headline_text = df.iloc[idx][text_column].lower()\n",
        "        company = df.iloc[idx][company_column].lower()\n",
        "        is_org = False\n",
        "\n",
        "        # 1. First, check for noise keywords\n",
        "        if any(word in headline_text for word in noise_keywords):\n",
        "            results.append(False)\n",
        "            continue\n",
        "\n",
        "        # 2. Then, check the entities detected by spaCy\n",
        "        for ent in doc.ents:\n",
        "            if company in ent.text.lower() and ent.label_ == 'ORG':\n",
        "                is_org = True\n",
        "                break\n",
        "\n",
        "        results.append(is_org)\n",
        "\n",
        "    return results\n",
        "\n",
        "# Test with our dataset\n",
        "df['is_org_batch'] = filter_org_articles_batch(df)\n",
        "\n",
        "print(\"Batch processing results:\")\n",
        "print(df[['headline', 'company', 'is_org_batch']])"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}